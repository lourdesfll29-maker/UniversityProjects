{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06022a67",
   "metadata": {},
   "source": [
    "CÓDIGO PRINCIPAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e23b60",
   "metadata": {},
   "source": [
    "Autores:\n",
    "- Belda Martínez, Marcos\n",
    "- Espert Cornejo, Ángela\n",
    "- Francés Llimerá, Lourdes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ef4c0",
   "metadata": {},
   "source": [
    "CALIBRACIÓN DE CÁMARAS Y SISTEMA ESTÉREO\n",
    "- Si los archivos de calibración no existen, se inicia automáticamente el proceso de calibración\n",
    "- Para cada cámara:\n",
    "    - Se detectan las esquinas en imágenes de un tablero de ajedrez\n",
    "    - Se calcula la matriz intrínseca (K) y los coeficientes de distorsión (dist)\n",
    "- Se calibra el sistema estéreo:\n",
    "    - Se calcula la relación entre las dos cámaras (rotación R, traslación T y matrices E y F)\n",
    "    - Se guardan los resultados en archivos \".npz\" para su posterior uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b251fd",
   "metadata": {},
   "source": [
    "EJECUCIÓN DEL SISTEMA\n",
    "\n",
    "1) Se verifica si existen archivos de calibración\n",
    "    - Si faltan, se realiza la calibración de las cámaras y sistema estéreo\n",
    "\n",
    "2) Se inicia la interfaz de triangulación\n",
    "    - Selección de puntos y cálculo de coordenadas 3D\n",
    "\n",
    "3) Se realiza la consulta por terminal\n",
    "    - \"Indica con la mano cuántos ítems desea recoger. Si desea salir, pulse ESC\"\n",
    "\n",
    "4) Detección de fingers\n",
    "    - Número de fingers levantados X\n",
    "\n",
    "5) Se confirma la selección por terminal\n",
    "    - \"Si desea X ítems, pulse ENTER. En caso contrario, pulse ESC\"\n",
    "        - Si se pulsa ENTER, se pasa al paso 6\n",
    "        - Si se pulsa ESC, se finaliza el programa\n",
    "\n",
    "6) Se escanea el escenario para obtener el centroide del pentágono verde\n",
    "    - Opción 1: captura de camara única (no maneja cambios de posicionamiento)\n",
    "    - Opción 2: tracking continuo hasta finalizar el proceso \n",
    "    - Opción 3: captura de camara cada vez que se va a recoger un ítem (tras cada pick & place)\n",
    "\n",
    "7) Comunicación con RoboDK del centroide del pentágono mediante MQTT\n",
    "\n",
    "8) Simulación del movimiento de pick & place X veces\n",
    "    - Se hace hide y show del ítem para simular su recogida y la aparición del siguiente ítem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be51042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries and file processing\n",
    "import os                                   # Handling of paths and files in the operating system\n",
    "from glob import glob                       # Searching for files based on patterns (e.g., *.jpg)\n",
    "\n",
    "# Computer vision and matrix libraries\n",
    "import cv2                                  # OpenCV: image and video processing\n",
    "import numpy as np                          # Numerical operations and array handling\n",
    "\n",
    "# Libraries for additional tasks\n",
    "import threading                            # For multithreading programming\n",
    "import queue                                # For handling data queues (e.g., for multithreading)\n",
    "import pybullet as p                        # Physics simulation\n",
    "import time                                 # Time handling and delays\n",
    "\n",
    "# MediaPipe for computer vision tasks (body tracking, etc.)\n",
    "# from mediapipe.tasks.python import vision   # Classes and functions for vision-related tasks\n",
    "# from mediapipe.tasks import python          # Additional Python-specific utilities (redundant in this context)\n",
    "import mediapipe as mp                      # Core MediaPipe module for building and running ML pipelines\n",
    "\n",
    "# Libraries for MQTT communication\n",
    "import paho.mqtt.client as mqtt             # MQTT client for network communication\n",
    "import json                                 # Handling data in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3bece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path of the project\n",
    "BASE_PATH = r\"C:\\Users\\137ma\\Desktop\\Trabajo_Final\"\n",
    "\n",
    "# Path to the \"data\" folder within the project\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
    "\n",
    "# Create the \"data\" folder if it does not exist\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "    print(f\"folder created: {DATA_PATH}\")\n",
    "\n",
    "# Paths to the calibration files within the \"data\" folder\n",
    "CALIBRATION_PATH_L = os.path.join(DATA_PATH, \"calibration_camera_left.npz\")\n",
    "CALIBRATION_PATH_R = os.path.join(DATA_PATH, \"calibration_camera_right.npz\")\n",
    "CALIBRATION_PATH_STEREO = os.path.join(DATA_PATH, \"calibration_stereo.npz\")\n",
    "\n",
    "# Directories where the images for calibrating each camera are stored\n",
    "CALIBRATION_IMG_PATH_L = os.path.join(BASE_PATH, \"left_calibration_images\")\n",
    "CALIBRATION_IMG_PATH_R = os.path.join(BASE_PATH, \"right_calibration_images\")\n",
    "STEREO_IMG_PATH_L = os.path.join(BASE_PATH, \"stereo_images_L\")\n",
    "STEREO_IMG_PATH_R = os.path.join(BASE_PATH, \"stereo_images_R\")\n",
    "\n",
    "# Size of the chessboard pattern used for calibration (number of inner corners)\n",
    "BOARD_SIZE = (9, 6)\n",
    "\n",
    "# Physical size of each square in the pattern (in cm, mm, etc.)\n",
    "SQUARE_SIZE = 2.6\n",
    "\n",
    "# Valid image extensions for reading\n",
    "EXTENSION = [\"jpg\", \"jpeg\", \"bmp\"]\n",
    "\n",
    "# URL for the cameras\n",
    "CAM_URL_L = \"http://192.168.1.132:8080\"    # URL for the left camera\n",
    "CAM_URL_R = \"http://192.168.1.129:8080\"    # URL for the right camera\n",
    "\n",
    "# Size of the camera feed\n",
    "WIDTH = 640     # Width of the camera feed\n",
    "HEIGHT = 480    # Height of the camera feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28815f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cameraCalibration:\n",
    "    \"\"\"\n",
    "    A class for calibrating cameras individually and in stereo pairs.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the camera calibration class with default parameters.\n",
    "        \"\"\"\n",
    "        self.board_size = BOARD_SIZE        # Size of the chessboard pattern (number of inner corners)\n",
    "        self.square_size = SQUARE_SIZE      # Physical size of each square in the pattern\n",
    "        self.img_ext = EXTENSION            # Valid image extensions for reading\n",
    "\n",
    "    def individual_calibration(self, name, folder, save_path):\n",
    "        \"\"\"\n",
    "        Calibrates a single camera using a set of images of a chessboard pattern.\n",
    "        \"\"\"\n",
    "        # Display start message\n",
    "        print(\"\\n\\n\")\n",
    "        print(f\"Calibration file for camera {name} not found.\")\n",
    "        print(f\"Starting calibration for camera {name}...\")\n",
    "\n",
    "        # Define real-world 3D points of the chessboard (same for all images)\n",
    "        objp = np.zeros((self.board_size[0] * self.board_size[1], 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:self.board_size[0], 0:self.board_size[1]].T.reshape(-1, 2)\n",
    "        objp *= self.square_size  # Scale to the actual physical size\n",
    "\n",
    "        objpoints = []  # List of real-world 3D points\n",
    "        imgpoints = []  # List of detected 2D points in images\n",
    "\n",
    "        # Load all images with valid extensions\n",
    "        img = []\n",
    "        for ext in self.img_ext:\n",
    "            img.extend(sorted(glob(os.path.join(folder, f\"*.{ext}\"))))\n",
    "\n",
    "        # Check if images were found\n",
    "        if not img:\n",
    "            print(f\"ERROR: No images found in: {folder}\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Found {len(img)} images for calibrating camera {name}.\")\n",
    "\n",
    "        # Iterate over each image and detect chessboard corners\n",
    "        for idx, path in enumerate(img):\n",
    "            img = cv2.imread(path)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, self.board_size, None)\n",
    "\n",
    "            if ret:\n",
    "                # If corners are detected, refine them and save\n",
    "                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "                corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "            else:\n",
    "                print(f\"ERROR: Corners not detected in image: {os.path.basename(path)}\")\n",
    "\n",
    "        # At least 5 valid images are needed for calibration\n",
    "        if len(objpoints) < 5:\n",
    "            print(f\"Only detected patterns in {len(objpoints)} images. At least 5 are required.\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Using {len(objpoints)} valid images for calibration...\")\n",
    "\n",
    "        # Perform calibration using the detected points\n",
    "        img_shape = gray.shape[::-1]\n",
    "        ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_shape, None, None)\n",
    "\n",
    "        # Display the projection matrix for the first image\n",
    "        R = cv2.Rodrigues(rvecs[0])[0]\n",
    "        RT = np.concatenate((R, tvecs[0]), axis=1)\n",
    "        P = K @ RT\n",
    "        print(f\"\\nProjection matrix for camera {name}:\")\n",
    "        print(np.array2string(P, formatter={'float_kind': lambda x: f\"{x:8.3f}\"}))\n",
    "\n",
    "        # Calculate and display the reprojection error for each image\n",
    "        total_error = 0\n",
    "        for i in range(len(objpoints)):\n",
    "            projected_points, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], K, dist)\n",
    "            error = cv2.norm(imgpoints[i], projected_points, cv2.NORM_L2) / len(projected_points)\n",
    "            total_error += error\n",
    "            print(f\"Reprojection error for img {i+1}: {error:.4f} px\")\n",
    "\n",
    "        # Calculate the average reprojection error\n",
    "        reproj_error_avg = total_error / len(objpoints)\n",
    "        print(f\"\\nAverage reprojection error for camera {name}: {reproj_error_avg:.4f} px\")\n",
    "\n",
    "        # Save calibration parameters to a file\n",
    "        np.savez(save_path, K=K, dist=dist)\n",
    "        print(f\"Parameters saved to: {save_path}\")\n",
    "        print(\"\\n\\n\")\n",
    "        return True\n",
    "\n",
    "    def stereo_calibration(self, path_R, path_L, dir_R, dir_L, save_path):\n",
    "        \"\"\"\n",
    "        Calibrates a stereo camera system using individual calibration parameters.\n",
    "        \"\"\"\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Calibrating stereo system...\")\n",
    "\n",
    "        # Load individual calibration parameters\n",
    "        try:\n",
    "            right = np.load(path_R)\n",
    "            left = np.load(path_L)\n",
    "            K1, D1 = right[\"K\"], right[\"dist\"]\n",
    "            K2, D2 = left[\"K\"], left[\"dist\"]\n",
    "        except:\n",
    "            print(\"ERROR: Could not load individual calibrations.\")\n",
    "            return False\n",
    "\n",
    "        # Load pairs of images from both cameras\n",
    "        images_r = []\n",
    "        images_l = []\n",
    "        for ext in self.img_ext:\n",
    "            images_r.extend(sorted(glob(os.path.join(dir_R, f\"*.{ext}\"))))\n",
    "            images_l.extend(sorted(glob(os.path.join(dir_L, f\"*.{ext}\"))))\n",
    "\n",
    "        # Check if there are enough valid pairs\n",
    "        if len(images_r) != len(images_l) or len(images_r) < 5:\n",
    "            print(\"The stereo image folders do not contain enough valid pairs or are unbalanced.\")\n",
    "            return False\n",
    "\n",
    "        # Generate 3D points of the chessboard pattern\n",
    "        objp = np.zeros((self.board_size[0]*self.board_size[1], 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:self.board_size[0], 0:self.board_size[1]].T.reshape(-1, 2)\n",
    "        objp *= self.square_size\n",
    "\n",
    "        objpoints, imgpoints_l, imgpoints_r = [], [], []\n",
    "\n",
    "        # Detect corners in each pair of images (left and right)\n",
    "        for img1, img2 in zip(images_l, images_r):\n",
    "            im_l = cv2.imread(img1)\n",
    "            im_r = cv2.imread(img2)\n",
    "            gray_l = cv2.cvtColor(im_l, cv2.COLOR_BGR2GRAY)\n",
    "            gray_r = cv2.cvtColor(im_r, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            ret1, corners_l = cv2.findChessboardCorners(gray_l, self.board_size, None)\n",
    "            ret2, corners_r = cv2.findChessboardCorners(gray_r, self.board_size, None)\n",
    "\n",
    "            if ret1 and ret2:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints_l.append(corners_l)\n",
    "                imgpoints_r.append(corners_r)\n",
    "\n",
    "        # Check if there are enough valid pairs\n",
    "        if len(objpoints) < 5:\n",
    "            print(\"Not enough valid pairs for stereo calibration.\")\n",
    "            return False\n",
    "\n",
    "        # Perform stereo calibration with fixed individual parameters\n",
    "        img_shape = gray_l.shape[::-1]\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5)\n",
    "        flags = cv2.CALIB_FIX_INTRINSIC  # Do not recalculate K1 and K2\n",
    "\n",
    "        # Calibrate stereo: obtain rotation matrix, translation vector, essential and fundamental matrices\n",
    "        _, _, _, _, _, R, T, E, F = cv2.stereoCalibrate(\n",
    "            objpoints, imgpoints_l, imgpoints_r,\n",
    "            K1, D1, K2, D2, img_shape,\n",
    "            criteria=criteria, flags=flags\n",
    "        )\n",
    "\n",
    "        # Display the results\n",
    "        print(f\"\\nRotation matrix R:\\n{R}\")\n",
    "        print(f\"\\nTranslation vector T:\\n{T}\")\n",
    "        print(f\"\\nEssential matrix E:\\n{E}\")\n",
    "        print(f\"\\nFundamental matrix F:\\n{F}\")\n",
    "\n",
    "        # Save the results to a file\n",
    "        np.savez(save_path, K1=K1, D1=D1, K2=K2, D2=D2, R=R, T=T)\n",
    "        print(f\"\\nStereo calibration saved to: {save_path}\")\n",
    "        print(\"\\n\\n\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df750acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stereoInterface:\n",
    "    \"\"\"\n",
    "    A class for handling stereo camera operations, gesture detection, and robot communication.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the stereo interface with camera URLs and MQTT settings.\n",
    "        \"\"\"\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Initializing video\")\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        self.window = \"Main Program\"\n",
    "        self.height = 480\n",
    "        self.width = 640\n",
    "\n",
    "        self.cap_L = cv2.VideoCapture(CAM_URL_L)\n",
    "        self.cap_R = cv2.VideoCapture(CAM_URL_R)\n",
    "\n",
    "        self.frame_right = None\n",
    "        self.frame_left = None\n",
    "        \n",
    "        self.stopThreads = False            # Flag to stop threads\n",
    "        self.lock_frame = threading.Lock()  # Lock for thread-safe frame access\n",
    "        \n",
    "        self.ip = \"broker.emqx.io\"               # IP address for MQTT communication\n",
    "        self.sendTopic = \"robodk/position\"  # MQTT topic for sending positions\n",
    "        self.receiveTopic = \"robodk/state\"  # MQTT topic for receiving robot state\n",
    "        self.received = False               # Flag to check if a message has been received\n",
    "        self.robotState = True              # State of the robot\n",
    "\n",
    "        self.fingers = -1\n",
    "        self.position = None\n",
    "        self.gestureOn = True\n",
    "        self.triangulationOn = True\n",
    "        \n",
    "    def loadCalibration(self):\n",
    "        \"\"\"\n",
    "        Loads stereo calibration parameters from a file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = np.load(CALIBRATION_PATH_STEREO)\n",
    "            self.K1, self.D1 = data[\"K1\"], data[\"D1\"]   # Left camera intrinsic matrix and distortion coefficients\n",
    "            self.K2, self.D2 = data[\"K2\"], data[\"D2\"]   # Right camera intrinsic matrix and distortion coefficients\n",
    "            self.R, self.T = data[\"R\"], data[\"T\"]       # Rotation and translation matrices\n",
    "        except:\n",
    "            raise RuntimeError(\"ERROR: Could not load stereo calibration.\")\n",
    "\n",
    "    def capture_L(self):\n",
    "        \"\"\"\n",
    "        Captures frames from the left camera.\n",
    "        \"\"\"\n",
    "        while not self.stopThreads and self.cap_L.isOpened():\n",
    "            ret, frame = self.cap_L.read()\n",
    "            if ret:\n",
    "                with self.lock_frame:\n",
    "                    self.frame_left = frame.copy()     # Store the captured frame\n",
    "                     \n",
    "    def capture_R(self):\n",
    "        \"\"\"\n",
    "        Captures frames from the right camera.\n",
    "        \"\"\"\n",
    "        while not self.stopThreads and self.cap_R.isOpened():\n",
    "            ret, frame = self.cap_R.read()\n",
    "            if ret:\n",
    "                with self.lock_frame:\n",
    "                    self.frame_right = frame.copy()    # Store the captured frame\n",
    "      \n",
    "    def fingerCount(self, hand_landmarks):\n",
    "        \"\"\"\n",
    "        Counts the number of fingers raised in a hand.\n",
    "        \"\"\"\n",
    "        finger_tips_ids = [4, 8, 12, 16, 20]    # IDs of finger tips\n",
    "        count = 0\n",
    "        # Thumb\n",
    "        if hand_landmarks.landmark[finger_tips_ids[0]].x < hand_landmarks.landmark[finger_tips_ids[0] - 1].x:\n",
    "            count += 1\n",
    "        # Other fingers\n",
    "        for tip_id in finger_tips_ids[1:]:\n",
    "            if hand_landmarks.landmark[tip_id].y < hand_landmarks.landmark[tip_id - 2].y:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    def gestureDetection(self):\n",
    "        \"\"\"\n",
    "        Detects hand gestures using MediaPipe and counts fingers.\n",
    "        \"\"\"\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(static_image_mode = False,\n",
    "                               max_num_hands = 1,\n",
    "                               min_detection_confidence = 0.7, \n",
    "                               min_tracking_confidence = 0.5)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        last_fingers = -1\n",
    "        exit = 0\n",
    "\n",
    "        while not exit:\n",
    "            with self.lock_frame:\n",
    "                frame_L = self.frame_left.copy() if self.frame_left is not None else None\n",
    "                frame_R = self.frame_right.copy() if self.frame_right is not None else None\n",
    "\n",
    "            fingers_left = -1\n",
    "            fingers_right = -1\n",
    "            \n",
    "            # Process left camera\n",
    "            if frame_L is not None:\n",
    "                image_rgb_L = cv2.cvtColor(frame_L, cv2.COLOR_BGR2RGB)\n",
    "                results_L = hands.process(image_rgb_L)\n",
    "                if results_L.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results_L.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(frame_L, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                        fingers_left = self.fingerCount(hand_landmarks)\n",
    "\n",
    "            # Process right camera\n",
    "            if frame_R is not None:\n",
    "                image_rgb_R = cv2.cvtColor(frame_R, cv2.COLOR_BGR2RGB)\n",
    "                results_R = hands.process(image_rgb_R)\n",
    "                if results_R.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results_R.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(frame_R, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                        fingers_right = self.fingerCount(hand_landmarks)\n",
    "\n",
    "            # Choose the result with more fingers detected (or any preferred)\n",
    "            if fingers_left >= fingers_right and fingers_left != -1:\n",
    "                self.fingers = fingers_left\n",
    "                frame_to_show = frame_L\n",
    "            elif fingers_right != -1:\n",
    "                self.fingers = fingers_right\n",
    "                frame_to_show = frame_R\n",
    "            else:\n",
    "                self.fingers = -1\n",
    "                frame_to_show = frame_L if frame_L is not None else frame_R\n",
    "            \n",
    "            if frame_to_show is not None:\n",
    "                cv2.putText(frame_to_show, f'Fingers: {self.fingers}', (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)\n",
    "                cv2.imshow('Hand Detection', frame_to_show)\n",
    "\n",
    "            if self.fingers != last_fingers:\n",
    "                last_fingers = self.fingers\n",
    "                print(f\"If you want {self.fingers} items, press ENTER. Otherwise, press ESC\")\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if key == 13:       # ENTER\n",
    "                exit = 1\n",
    "                \n",
    "            elif key == 27:     # ESC\n",
    "                self.fingers = -2\n",
    "                exit = 1\n",
    "    \n",
    "        hands.close()\n",
    "        \n",
    "        self.gestureOn = False\n",
    "\n",
    "        if frame_to_show is not None:\n",
    "            cv2.destroyWindow('Hand Detection')\n",
    "\n",
    "    def getCentroid(self, frame):\n",
    "        \"\"\"\n",
    "        Detects the centroid of a green object in the frame.\n",
    "        \"\"\"\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "                \n",
    "        # Define the green color range in HSV\n",
    "        lower_green = np.array([35, 50, 200])   # Minimum green value\n",
    "        upper_green = np.array([80, 255, 255])  # Maximum green value\n",
    "        \n",
    "        # Create a mask to filter pixels within the green color range\n",
    "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        \n",
    "        # Filter noise using morphological operations\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        best_bbox = None\n",
    "        \n",
    "        # Filter contours by size and aspect ratio to avoid noise\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            area = w * h\n",
    "            aspect_ratio = w / float(h)\n",
    "            \n",
    "            # Filter by size and aspect ratio to avoid incorrect detections\n",
    "            if 300 < area < 8000 and 0.5 < aspect_ratio < 1.5:\n",
    "                best_bbox = (x, y, w, h)\n",
    "        \n",
    "        if best_bbox is not None:\n",
    "            p1 = (int(best_bbox[0]), int(best_bbox[1]))\n",
    "            p2 = (int(best_bbox[0] + best_bbox[2]), int(best_bbox[1] + best_bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "            \n",
    "            # Calculate centroid of the bounding box\n",
    "            centroid_x = int((p1[0] + p2[0]) / 2)\n",
    "            centroid_y = int((p1[1] + p2[1]) / 2)\n",
    "            centroid = (centroid_x, centroid_y)\n",
    "\n",
    "            return centroid \n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def triangulation(self, centroid_L, centroid_R):\n",
    "        \"\"\"\n",
    "        Performs triangulation to estimate the 3D position of a point.\n",
    "        \"\"\"\n",
    "        point_3d = None\n",
    "\n",
    "        display_L = self.frame_left.copy()\n",
    "        display_R = self.frame_right.copy()\n",
    "\n",
    "        if centroid_L is not None:\n",
    "            cv2.circle(display_L, centroid_L, 5, (0, 255, 0), -1)   # centroid_L[0]\n",
    "        if centroid_R is not None:\n",
    "            cv2.circle(display_R, centroid_R, 5, (0, 255, 0), -1)   # centroid_R[0]\n",
    "\n",
    "        cv2.imshow(\"Left Camera Centroid\", display_L)\n",
    "        cv2.imshow(\"Right Camera Centroid\", display_R)\n",
    "\n",
    "        if centroid_L is not None and centroid_R is not None:\n",
    "            # Undistort points\n",
    "            ptsL_np = np.array(centroid_L, dtype=np.float32).reshape(-1, 1, 2)\n",
    "            ptsR_np = np.array(centroid_R, dtype=np.float32).reshape(-1, 1, 2)\n",
    "            undistL = cv2.undistortPoints(ptsL_np, self.K1, self.D1, P=self.K1)\n",
    "            undistR = cv2.undistortPoints(ptsR_np, self.K2, self.D2, P=self.K2)\n",
    "\n",
    "            # Projection matrix for each camera\n",
    "            P1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "            P2 = np.hstack((self.R, self.T))\n",
    "            P1 = self.K1 @ P1\n",
    "            P2 = self.K2 @ P2\n",
    "\n",
    "            # Triangulation\n",
    "            point_4d = cv2.triangulatePoints(P1, P2, undistL, undistR)\n",
    "            point_3d = point_4d[:3] / point_4d[3]\n",
    "\n",
    "            print(f\"Estimated 3D coordinates: {point_3d.ravel()}\")\n",
    "            self.triangulationOn = False\n",
    "\n",
    "        return point_3d\n",
    "        \n",
    "    def centroidAdquisition(self):\n",
    "        \"\"\"\n",
    "        Acquires centroids from both cameras and performs triangulation.\n",
    "        \"\"\"\n",
    "        centroid_L = self.getCentroid(self.frame_left)\n",
    "        centroid_R = self.getCentroid(self.frame_right)\n",
    "        \n",
    "        \"\"\"\n",
    "        if not centroid_L or not centroid_R:\n",
    "            print(\"ERROR: Centroid not detected in one or both cameras.\")\n",
    "            c.put(-1)\n",
    "        \"\"\"\n",
    "        \n",
    "        while centroid_L is None and centroid_R is None:\n",
    "            centroid_L = self.getCentroid(self.frame_left)\n",
    "            centroid_R = self.getCentroid(self.frame_right)\n",
    "            print(\"Couldn't detect object\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\"Object detected, triangulation started\")\n",
    "\n",
    "        triangulatedPosition = self.triangulation(centroid_L, centroid_R)\n",
    "        \n",
    "        if triangulatedPosition is None:\n",
    "            print(\"ERROR: Triangulation failed.\")\n",
    "            self.position = None\n",
    "        \n",
    "        self.position = triangulatedPosition # x, y, z\n",
    "            \n",
    "    def sendPosition(self, ip, topic, pos):\n",
    "        \"\"\"\n",
    "        Sends the 3D position to RoboDK via MQTT.\n",
    "        \"\"\"\n",
    "        client = mqtt.Client()\n",
    "        try:\n",
    "            client.connect(ip, 1883, 60)\n",
    "            payload = json.dumps({\"x\": float(pos[0]), \"y\": float(pos[1]), \"z\": float(pos[2])})\n",
    "            client.publish(topic, payload)\n",
    "            print(f\"Sent to RoboDK: {payload}\")\n",
    "            client.disconnect()\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not send message to RoboDK: {e}\")\n",
    "       \n",
    "    # Callback when the client receives a CONNACK response from the server\n",
    "    def on_connect(self, client, userdata, flags, rc):\n",
    "        print(f\"Connected with result code {rc}\")\n",
    "        client.subscribe(self.receiveTopic)   \n",
    "        \n",
    "    # Callback when a message is received on a subscribed topic\n",
    "    def on_message(self, client, userdata, msg):\n",
    "        payload = msg.payload.decode('utf-8')\n",
    "        try:\n",
    "            self.robotState = bool(int(payload)) \n",
    "            print(f\"Received from RoboDK: {self.robotState}\")\n",
    "            self.received = True\n",
    "        except ValueError:\n",
    "            print(\"Received invalid payload. Expected 0 or 1.\")\n",
    "        \n",
    "    def getRobotInfo(self, ip):\n",
    "        \"\"\"\n",
    "        Retrieves the robot's state from RoboDK via MQTT.\n",
    "        \"\"\"\n",
    "        client = mqtt.Client()\n",
    "        client.on_connect = self.on_connect\n",
    "        client.on_message = self.on_message\n",
    "\n",
    "        try:\n",
    "            client.connect(ip, 1883, 60)\n",
    "            client.loop_start()\n",
    "\n",
    "            # Wait until we receive the message\n",
    "            while self.robotState:\n",
    "                time.sleep(1)\n",
    "\n",
    "            client.loop_stop()\n",
    "            client.disconnect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not connect to RoboDK: {e}\")\n",
    "    \n",
    "    def releaseAll(self):\n",
    "        \"\"\"\n",
    "        Releases all resources and stops threads.\n",
    "        \"\"\"\n",
    "        self.stopThreads = True\n",
    "        self.cap_L.release()\n",
    "        self.cap_R.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def videoCapture(self):\n",
    "        while self.robotState:\n",
    "            # Capture one image from each camera\n",
    "            with self.lock_frame:\n",
    "                img_L = self.frame_left\n",
    "                img_R = self.frame_right\n",
    "\n",
    "            if img_L is None or img_R is None:\n",
    "                print(\"ERROR: No image captured.\")\n",
    "                continue\n",
    "\n",
    "            # Resize images to same size\n",
    "            resized_L = cv2.resize(img_L, (self.width, self.height))\n",
    "            resized_R = cv2.resize(img_R, (self.width, self.height))\n",
    "\n",
    "            # Combine both images side-by-side\n",
    "            combined = np.hstack((resized_L , resized_R))\n",
    "            cv2.imshow(self.window, combined)\n",
    "            cv2.waitKey(1)\n",
    "            \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def robotCommunication(self):\n",
    "        while self.robotState:\n",
    "            if not self.gestureOn:\n",
    "                if self.fingers == -1:\n",
    "                    print(\"ERROR: Detection failed, exiting...\")\n",
    "                elif self.fingers == -2:\n",
    "                    print(\"Exiting the program...\")\n",
    "                else:\n",
    "                    centroidThread = threading.Thread(target = self.centroidAdquisition)\n",
    "                    centroidThread.start()\n",
    "\n",
    "                    centroidThread.join()\n",
    "\n",
    "                    if self.position is not None:\n",
    "\n",
    "                        self.sendPosition(self.ip, self.sendTopic, self.position)\n",
    "                        time.sleep(1)\n",
    "\n",
    "                        print(f\"Robot picking up {self.fingers} at position [{self.position[0]}, {self.position[1]}, {self.position[2]}]\")\n",
    "                        self.getRobotInfo(self.ip)\n",
    "\n",
    "                        print(\"Process completed, closing program...\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    def mainProgram(self):\n",
    "        \"\"\"\n",
    "        Main program logic for gesture detection, centroid acquisition, and robot communication.\n",
    "        \"\"\"\n",
    "        cv2.namedWindow(self.window, cv2.WINDOW_NORMAL)\n",
    "        self.loadCalibration()\n",
    "        \n",
    "        camera_L = threading.Thread(target = self.capture_L)\n",
    "        camera_R = threading.Thread(target = self.capture_R)\n",
    "        camera_L.start()\n",
    "        camera_R.start()\n",
    "\n",
    "        time.sleep(1)        \n",
    "        \n",
    "        print(\"Indicate with your hand how many items you want to pick up. Press ESC to exit\")        \n",
    "        gestures = threading.Thread(target = self.gestureDetection)  \n",
    "        gestures.start()\n",
    "        \n",
    "        robot_communication = threading.Thread(target = self.robotCommunication)  \n",
    "        robot_communication.start()\n",
    "\n",
    "        self.videoCapture()\n",
    "\n",
    "        gestures.join()\n",
    "        robot_communication.join()\n",
    "        camera_L.join()\n",
    "        camera_R.join()\n",
    "        self.releaseAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f20d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Verifying calibration files...\n",
      "\n",
      "\n",
      "\n",
      "Initializing video\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    # Start message to indicate that necessary files are being verified\n",
    "    print(\"\\n\\nVerifying calibration files...\")\n",
    "\n",
    "    # Create an instance of the calibrator with chessboard parameters\n",
    "    calibration = cameraCalibration()\n",
    "\n",
    "    # Variable to determine if any camera needs to be recalibrated\n",
    "    recalibrate = False\n",
    "\n",
    "    # === Verify and calibrate the left camera if necessary ===\n",
    "    if not os.path.exists(CALIBRATION_PATH_L):\n",
    "        recalibrate |= not calibration.individual_calibration(\"Left\", CALIBRATION_IMG_PATH_L, CALIBRATION_PATH_L)\n",
    "\n",
    "    # === Verify and calibrate the right camera if necessary ===\n",
    "    if not os.path.exists(CALIBRATION_PATH_R):\n",
    "        recalibrate |= not calibration.individual_calibration(\"Right\", CALIBRATION_IMG_PATH_R, CALIBRATION_PATH_R)\n",
    "\n",
    "    # If individual calibration files still do not exist after attempting to calibrate, exit with an error\n",
    "    if not os.path.exists(CALIBRATION_PATH_L) or not os.path.exists(CALIBRATION_PATH_R):\n",
    "        print(\"ERROR: Individual calibration failed.\")\n",
    "        exit()\n",
    "\n",
    "    # === Verify and calibrate the stereo system if necessary ===\n",
    "    # This is done if the stereo calibration file does not exist or if any camera was recalibrated\n",
    "    if not os.path.exists(CALIBRATION_PATH_STEREO) or recalibrate:\n",
    "        if not calibration.stereo_calibration(\n",
    "            CALIBRATION_PATH_R, \n",
    "            CALIBRATION_PATH_L,\n",
    "            STEREO_IMG_PATH_R, \n",
    "            STEREO_IMG_PATH_L,\n",
    "            CALIBRATION_PATH_STEREO\n",
    "        ):\n",
    "            print(\"ERROR: Stereo calibration failed.\")\n",
    "            exit()\n",
    "    \n",
    "    # Create an instance of the stereo interface        \n",
    "    mainProgram = stereoInterface()\n",
    "    \n",
    "    # Run the main program logic\n",
    "    mainProgram.mainProgram()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open3d_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
